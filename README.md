Dá»° ÃN NGHIÃŠN Cá»¨U PHÃT HIá»†N HÃŒNH áº¢NH GIáº¢ Máº O (DEEPFAKE) Báº°NG Há»ŒC SÃ‚U
<p align="center"> <img src="https://img.shields.io/badge/Python-3.11.9-blue" alt="Python"> <img src="https://img.shields.io/badge/TensorFlow-2.20.0-orange" alt="TensorFlow"> <img src="https://img.shields.io/badge/Accuracy-95%25-brightgreen" alt="Accuracy"> <img src="https://img.shields.io/badge/Status-Completed-success" alt="Status"> </p>
ğŸ“‹ Má»¥c lá»¥c
1. Tá»•ng quan dá»± Ã¡n

2. Cáº¥u hÃ¬nh há»‡ thá»‘ng vÃ  chuáº©n bá»‹ dá»¯ liá»‡u

2.1. Cáº¥u hÃ¬nh há»‡ thá»‘ng

2.2. Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u

3. Kiáº¿n trÃºc mÃ´ hÃ¬nh

3.1. EfficientNetB0 Architecture

3.2. ThÃ´ng sá»‘ ká»¹ thuáº­t

4. QuÃ¡ trÃ¬nh training

4.1. Chia dá»¯ liá»‡u

4.2. Data Pipeline

4.3. Training Configuration

5. Káº¿t quáº£ vÃ  Ä‘Ã¡nh giÃ¡

5.1. Performance Metrics

5.2. Confusion Matrix

6. ÄÃ³ng gÃ³p chÃ­nh cá»§a nghiÃªn cá»©u

7. ThÃ¡ch thá»©c vÃ  giáº£i phÃ¡p

7.1. ThÃ¡ch thá»©c

7.2. Giáº£i phÃ¡p

8. HÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai

9. Káº¿t luáº­n

1. Tá»•ng quan dá»± Ã¡n
Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ phÃ¡t hiá»‡n hÃ¬nh áº£nh deepfake, sá»­ dá»¥ng kiáº¿n trÃºc EfficientNetB0 lÃ m backbone. NghiÃªn cá»©u sá»­ dá»¥ng táº­p dá»¯ liá»‡u FaceForensics++ tá»« Kaggle vÃ  Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t tÄƒng cÆ°á»ng dá»¯ liá»‡u cÃ¹ng vá»›i mÃ´ hÃ¬nh GAN Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t phÃ¡t hiá»‡n.

ğŸ¯ Má»¥c tiÃªu chÃ­nh:
XÃ¢y dá»±ng há»‡ thá»‘ng phÃ¡t hiá»‡n deepfake tá»± Ä‘á»™ng

Äáº¡t Ä‘á»™ chÃ­nh xÃ¡c cao trÃªn táº­p dá»¯ liá»‡u thá»­ nghiá»‡m

Tá»‘i Æ°u hÃ³a cho há»‡ thá»‘ng khÃ´ng cÃ³ GPU

2. Cáº¥u hÃ¬nh há»‡ thá»‘ng vÃ  chuáº©n bá»‹ dá»¯ liá»‡u
2.1. Cáº¥u hÃ¬nh há»‡ thá»‘ng
ThÃ nh pháº§n	ThÃ´ng sá»‘ ká»¹ thuáº­t
Há»‡ Ä‘iá»u hÃ nh	Windows 10
RAM	15.78 GB
CPU	6 cores váº­t lÃ½
GPU	KhÃ´ng cÃ³ GPU (cháº¡y hoÃ n toÃ n trÃªn CPU)
TensorFlow	Version 2.20.0
Python	Version 3.11.9
2.2. Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u
a) TrÃ­ch xuáº¥t khuÃ´n máº·t tá»« video
python
- Sá»­ dá»¥ng MTCNN Ä‘á»ƒ tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  cáº¯t khuÃ´n máº·t tá»« video
- Xá»­ lÃ½ 200 video tháº­t vÃ  200 video giáº£ máº¡o
- CÃ i Ä‘áº·t: Xá»­ lÃ½ má»—i khung hÃ¬nh thá»© 10 Ä‘á»ƒ giáº£m táº£i
- Káº¿t quáº£: 16,789 áº£nh tháº­t vÃ  14,142 áº£nh giáº£
b) Chuáº©n hÃ³a kÃ­ch thÆ°á»›c áº£nh
python
- Resize táº¥t cáº£ áº£nh vá» kÃ­ch thÆ°á»›c 224x224 pixel
- Sá»­ dá»¥ng interpolation cv2.INTER_AREA Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng
c) TÄƒng cÆ°á»ng dá»¯ liá»‡u
Traditional Augmentation (Táº¡o thÃªm 2,000 áº£nh giáº£):

Láº­t ngang (50% xÃ¡c suáº¥t)

Xoay nháº¹ (-15 Ä‘áº¿n +15 Ä‘á»™)

Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng (0.8-1.2)

Zoom nháº¹ (0.85-1.0)

DCGAN Augmentation (Huáº¥n luyá»‡n DCGAN Ä‘á»ƒ táº¡o áº£nh giáº£ má»›i):

PhiÃªn báº£n 64x64: Training nhanh, sau Ä‘Ã³ upscale lÃªn 224x224

PhiÃªn báº£n 224x224: Training trá»±c tiáº¿p á»Ÿ Ä‘á»™ phÃ¢n giáº£i má»¥c tiÃªu

Táº¡o 2,000 áº£nh giáº£ má»›i tá»« má»—i mÃ´ hÃ¬nh

3. Kiáº¿n trÃºc mÃ´ hÃ¬nh
3.1. EfficientNetB0 Architecture








Backbone (Feature Extractor):
Base model: EfficientNetB0 (khÃ´ng bao gá»“m top layer)

Transfer Learning: Sá»­ dá»¥ng pre-trained weights tá»« ImageNet

Fine-tuning: Chá»‰ unfreeze 50 layer cuá»‘i Ä‘á»ƒ tinh chá»‰nh

Classification Head:
Global Average Pooling 2D: Chuyá»ƒn Ä‘á»•i feature maps 7x7x1280 thÃ nh vector 1280

Batch Normalization: á»”n Ä‘á»‹nh quÃ¡ trÃ¬nh training

Dropout (0.5): NgÄƒn cháº·n overfitting

Dense Layer (512 units, ReLU): Há»c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p

Dropout (0.4): ThÃªm regularization

Output Layer (1 unit, Sigmoid): PhÃ¢n loáº¡i nhá»‹ phÃ¢n (0: Real, 1: Fake)

3.2. ThÃ´ng sá»‘ ká»¹ thuáº­t
ThÃ´ng sá»‘	GiÃ¡ trá»‹
Total Parameters	4,711,076 (17.97 MB)
Trainable Parameters	3,185,809 (12.15 MB)
Non-trainable Parameters	1,525,267 (5.82 MB)
Input Shape	(224, 224, 3)
Output Shape	(1,) - XÃ¡c suáº¥t giáº£ máº¡o
4. QuÃ¡ trÃ¬nh training
4.1. Chia dá»¯ liá»‡u
Tá»•ng sá»‘ áº£nh: 32,931 áº£nh

16,789 áº£nh tháº­t

16,142 áº£nh giáº£

Tá»· lá»‡ chia (80/10/10):

Split	Sá»‘ lÆ°á»£ng áº£nh	Tá»· lá»‡
Training	26,344	80%
Validation	3,293	10%
Testing	3,294	10%
4.2. Data Pipeline
Data Augmentation trong training:

Random horizontal flip

Random rotation (10%)

Random zoom (10%)

Random contrast (10%)

4.3. Training Configuration
Tham sá»‘	GiÃ¡ trá»‹
Batch Size	8 (tá»‘i Æ°u cho RAM)
Epochs	20
Optimizer	Adam vá»›i Cosine Decay Learning Rate
Initial learning rate	1e-4
Alpha	0.01
Loss Function	Binary Crossentropy
Callbacks:

ModelCheckpoint: LÆ°u model tá»‘t nháº¥t dá»±a trÃªn val_accuracy

EarlyStopping: Patience = 5 epochs

5. Káº¿t quáº£ vÃ  Ä‘Ã¡nh giÃ¡
5.1. Performance Metrics
Training Progress:
Metric	GiÃ¡ trá»‹
Final Training Accuracy	94.45%
Final Validation Accuracy	94.23%
Best Validation Accuracy	94.32% (Epoch 19)
Lowest Validation Loss	0.1140 (Epoch 17)
Testing Results (trÃªn 3,091 áº£nh):
text
              precision    recall  f1-score   support

        Fake       0.97      0.92      0.95      1679
        Real       0.92      0.97      0.94      1412

    accuracy                           0.95      3091
   macro avg       0.94      0.95      0.95      3091
weighted avg       0.95      0.95      0.95      3091
5.2. Confusion Matrix
Predicted Fake	Predicted Real
Actual Fake	92%	8%
Actual Real	3%	97%
Káº¿t quáº£ chi tiáº¿t:

True Positive (Fake correctly identified): 92%

True Negative (Real correctly identified): 97%

Overall Accuracy: 95%

6. ÄÃ³ng gÃ³p chÃ­nh cá»§a nghiÃªn cá»©u
âœ… Xá»­ lÃ½ dá»¯ liá»‡u toÃ n diá»‡n: Tá»± Ä‘á»™ng trÃ­ch xuáº¥t khuÃ´n máº·t, chuáº©n hÃ³a vÃ  tÄƒng cÆ°á»ng dá»¯ liá»‡u

âœ… Káº¿t há»£p nhiá»u phÆ°Æ¡ng phÃ¡p augmentation: Sá»­ dá»¥ng cáº£ traditional augmentation vÃ  GAN-based augmentation

âœ… Tá»‘i Æ°u hÃ³a training trÃªn CPU: Äiá»u chá»‰nh batch size vÃ  pipeline Ä‘á»ƒ cháº¡y hiá»‡u quáº£ trÃªn há»‡ thá»‘ng khÃ´ng cÃ³ GPU

âœ… Hiá»‡u suáº¥t cao: Äáº¡t 95% accuracy trÃªn táº­p test vá»›i mÃ´ hÃ¬nh nháº¹ (18MB)

âœ… Kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t: Precision vÃ  recall cÃ¢n báº±ng giá»¯a hai lá»›p

7. ThÃ¡ch thá»©c vÃ  giáº£i phÃ¡p
7.1. ThÃ¡ch thá»©c
ThÃ¡ch thá»©c	MÃ´ táº£
KhÃ´ng cÃ³ GPU	Training cháº­m trÃªn CPU
Máº¥t cÃ¢n báº±ng dá»¯ liá»‡u	Sá»‘ lÆ°á»£ng áº£nh tháº­t nhiá»u hÆ¡n áº£nh giáº£
Memory constraints	RAM háº¡n cháº¿ (15.78 GB)
7.2. Giáº£i phÃ¡p
Giáº£i phÃ¡p	Hiá»‡u quáº£
Tá»‘i Æ°u batch size	Sá»­ dá»¥ng batch size nhá» (8) phÃ¹ há»£p vá»›i RAM
Data augmentation	Táº¡o thÃªm áº£nh giáº£ Ä‘á»ƒ cÃ¢n báº±ng dataset
Efficient data pipeline	Sá»­ dá»¥ng tf.data.Dataset vá»›i prefetch Ä‘á»ƒ tá»‘i Æ°u I/O
Model optimization	Chá»n EfficientNetB0 - mÃ´ hÃ¬nh nháº¹ nhÆ°ng hiá»‡u quáº£
8. HÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai
ğŸ”¬ NghiÃªn cá»©u tiáº¿p theo:
NÃ¢ng cáº¥p pháº§n cá»©ng: Sá»­ dá»¥ng GPU Ä‘á»ƒ training nhanh hÆ¡n

Thá»­ nghiá»‡m vá»›i cÃ¡c kiáº¿n trÃºc khÃ¡c: Vision Transformers, ResNet variants

Má»Ÿ rá»™ng dataset: Sá»­ dá»¥ng thÃªm cÃ¡c dataset deepfake khÃ¡c

ğŸš€ á»¨ng dá»¥ng thá»±c táº¿:
PhÃ¡t triá»ƒn cho video: Má»Ÿ rá»™ng tá»« phÃ¡t hiá»‡n áº£nh sang phÃ¡t hiá»‡n video

Triá»ƒn khai thá»±c táº¿: XÃ¢y dá»±ng API hoáº·c á»©ng dá»¥ng cho kiá»ƒm tra real-time

TÃ­ch há»£p há»‡ thá»‘ng: Káº¿t há»£p vá»›i cÃ¡c há»‡ thá»‘ng báº£o máº­t hiá»‡n cÃ³

ğŸ“Š Cáº£i thiá»‡n hiá»‡u suáº¥t:
Ensemble models: Káº¿t há»£p nhiá»u mÃ´ hÃ¬nh Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c

Explainable AI: PhÃ¡t triá»ƒn tÃ­nh nÄƒng giáº£i thÃ­ch quyáº¿t Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh

Real-time optimization: Tá»‘i Æ°u hÃ³a cho inference tá»‘c Ä‘á»™ cao

9. Káº¿t luáº­n
ğŸ‰ ThÃ nh tá»±u Ä‘áº¡t Ä‘Æ°á»£c:
NghiÃªn cá»©u Ä‘Ã£ thÃ nh cÃ´ng trong viá»‡c phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh phÃ¡t hiá»‡n deepfake hiá»‡u quáº£ sá»­ dá»¥ng EfficientNetB0. MÃ´ hÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c 95% trÃªn táº­p test, chá»©ng minh kháº£ nÄƒng phÃ¢n biá»‡t tá»‘t giá»¯a áº£nh tháº­t vÃ  áº£nh giáº£ máº¡o.

ğŸ’¡ PhÆ°Æ¡ng phÃ¡p Ä‘á»™t phÃ¡:
PhÆ°Æ¡ng phÃ¡p káº¿t há»£p giá»¯a transfer learning, data augmentation truyá»n thá»‘ng vÃ  GAN-based augmentation Ä‘Ã£ mang láº¡i káº¿t quáº£ áº¥n tÆ°á»£ng ngay cáº£ trong Ä‘iá»u kiá»‡n pháº§n cá»©ng háº¡n cháº¿.

ğŸ—ï¸ ÄÃ³ng gÃ³p chÃ­nh:
Dá»± Ã¡n cung cáº¥p má»™t pipeline hoÃ n chá»‰nh tá»« xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº¿n training vÃ  evaluation, cÃ³ thá»ƒ dá»… dÃ ng tÃ¡i sá»­ dá»¥ng vÃ  má»Ÿ rá»™ng cho cÃ¡c nghiÃªn cá»©u tÆ°Æ¡ng tá»± trong tÆ°Æ¡ng lai.

ğŸŒŸ TÃ¡c Ä‘á»™ng:
NghiÃªn cá»©u nÃ y Ä‘Ã³ng gÃ³p vÃ o viá»‡c phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ phÃ¡t hiá»‡n deepfake tá»± Ä‘á»™ng, há»— trá»£ cÃ¡c ná»— lá»±c chá»‘ng láº¡i thÃ´ng tin sai lá»‡ch vÃ  báº£o vá»‡ tÃ­nh xÃ¡c thá»±c cá»§a ná»™i dung ká»¹ thuáº­t sá»‘.

<p align="center"> <em>ğŸ“Š MÃ´ hÃ¬nh Ä‘áº¡t 95% Ä‘á»™ chÃ­nh xÃ¡c - Sáºµn sÃ ng cho á»©ng dá»¥ng thá»±c táº¿</em> </p><p align="center"> <img src="https://img.shields.io/badge/Made%20with-Python-3776AB.svg?style=for-the-badge&logo=python&logoColor=white" alt="Made with Python"> <img src="https://img.shields.io/badge/Powered%20by-TensorFlow-FF6F00.svg?style=for-the-badge&logo=tensorflow&logoColor=white" alt="Powered by TensorFlow"> <img src="https://img.shields.io/badge/Research-Complete-success.svg?style=for-the-badge" alt="Research Complete"> </p>
